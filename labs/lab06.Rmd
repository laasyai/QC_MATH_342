---
title: "Lab 6"
author: "Laasya Indrakanti"
output: pdf_document
---


#Visualization with the package ggplot2

I highly recommend using the [ggplot cheat sheet](https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf) as a reference resource. You will see questions that say "Create the best-looking plot". Among other things you may choose to do, remember to label the axes using real English, provide a title and subtitle. You may want to pick a theme and color scheme that you like and keep that constant throughout this lab. The default is fine if you are running short of time.

Load up the `GSSvocab` dataset in package `carData` as `X` and drop all observations with missing measurements. This will be a very hard visualization exercise since there is not a good model for vocab.

```{r}
pacman::p_load(carData)

X = carData::GSSvocab
X = na.omit(X)
skimr::skim(X)
```

Briefly summarize the documentation on this dataset. What is the data type of each variable? What do you think is the response variable the collectors of this data had in mind?

The data contains 27360 observations and 8 independent variables. Year is numeric, gender is binary, nativeborn is binary, and agegroup and educgroup are categorical. The response variable is vocab which is numeric.


Create two different plots and identify the best-looking plot you can to examine the `age` variable. Save the best looking plot as an appropriately-named PDF.

```{r}

pacman::p_load(ggplot2)
plot_age = ggplot(X) +
  aes(age)
plot_age + geom_histogram()
plot_age + geom_dotplot()
plot_age + geom_density()

  
```

Create two different plots and identify the best looking plot you can to examine the `vocab` variable. Save the best looking plot as an appropriately-named PDF.

```{r}
pacman::p_load(ggplot2)
plot_age = ggplot(X) +
  aes(vocab)
plot_age + geom_histogram()
plot_age + geom_dotplot()
plot_age + geom_density()
X$vocab_factor = factor(X$vocab)
ggplot(X) + aes(vocab_factor) + geom_bar()
```

Create the best-looking plot you can to examine the `ageGroup` variable by `gender`. Does there appear to be an association? There are many ways to do this.

```{r}
ggplot(X) + aes(x = ageGroup) + geom_bar() + facet_grid(gender~ .)

```

Create the best-looking plot you can to examine the `vocab` variable by `age`. Does there appear to be an association?

```{r}
ggplot(X) + aes(x = age, y = vocab_factor) + geom_boxplot()
```

Add an estimate of $f(x)$ using the smoothing geometry to the previous plot. Does there appear to be an association now?

```{r}
ggplot(X) + aes(x = age, y = vocab) + geom_point() + geom_smooth()
```

Using the plot from the previous question, create the best looking plot overloading with variable `gender`. Does there appear to be an interaction of `gender` and `age`?

```{r}
ggplot(X) + aes(x = age, y = vocab, color = gender) + geom_smooth()
```


Using the plot from the previous question, create the best looking plot overloading with variable `nativeBorn`. Does there appear to be an interaction of `nativeBorn` and `age`?

```{r}
ggplot(X) + aes(x = age, y = vocab, color = nativeBorn) + geom_smooth()
```

Create two different plots and identify the best-looking plot you can to examine the `vocab` variable by `educGroup`. Does there appear to be an association?

```{r}
ggplot(X) + aes(x = educGroup, y = vocab) + geom_boxplot()
```

Using the best-looking plot from the previous question, create the best looking overloading with variable `gender`. Does there appear to be an interaction of `gender` and `educGroup`?
yes

```{r}
ggplot(X) + aes(x = educGroup, y = vocab, fill = gender) + geom_boxplot()
```

Using facets, examine the relationship between `vocab` and `ageGroup`. You can drop year level `(Other)`. Are we getting dumber?

```{r}
X_new = subset(X, ageGroup != "(Other)")
ggplot(X_new, aes(x = vocab)) + geom_density() + facet_wrap(~ ageGroup)
```


#Logistic Regression

Let's consider the Pima Indians Diabetes dataset from 1988:

```{r}
?MASS::Pima.tr2
pima = na.omit(MASS::Pima.tr2)
skimr::skim(pima)
y = ifelse(pima$type == "Yes", 1, 0)
X = cbind(1, pima[, 1 : 7])
```

Note the missing data. We will learn about how to handle missing data towards the end of the course. For now, replace, the missing data in the design matrix X with the average of the feature x_dot,j. You can check that this worked with the table commands at the end of the chunk:

```{r}
table(X$bp, useNA = "always")
table(X$skin, useNA = "always")
table(X$bmi, useNA = "always")
```

Now let's fit a log-odds linear model of y=1 (type is "diabetic") on just the `glu` variable. Use `optim` to fit the model.

```{r}
x = pima$glu
log_logistic_prob = function(w){
  -sum(-y*log(1+exp(-w[1]-w[2]*x))-(1-y)*log(1+exp(w[1]+w[2]*x)))
}
optim(c(0, 0), log_logistic_prob)$par
```

Masters students: write a `fit_logistic_regression` function which takes in X, y and returns b which uses the optimization routine.

```{r}
fit_logistic_regression = function(X, y){
  b = #TO-DO
  b
}
```

Run a logistic regression of y=1 (type is "diabetic") on just the `glu` variable using R's built-in function and report b_0, b_1.

```{r}
b = coef(glm(y~x, family = "binomial"))
```

Comment on how close the results from R's built-in function was and your optimization call.

it was close

Interpret the value of b_1 from R's built-in function.

A one unit increase in x results in a 0.04 increase in log odds of having diabetes

Interpret the value of b_0 from R's built-in function.

the log-odds of having diabetes when glu is 0 is -5.5

Plot the probability of y=1 from the minimum value of `glu` to the maximum value of `glu`.

```{r}
min(x)
max(x)
res = .1
x_stars = seq(from = min(x), to = max(x), by = res)
log_odds_hat = cbind(1, x_stars)%*%b
p_hat = 1/(1+exp(-log_odds_hat))
pacman::p_load(ggplot2)
ggplot(data.frame(glucose = x_stars, pred_prob_diab = p_hat)) +
  aes(x = glucose, y= pred_prob_diab) +
  geom_line()
```

Run a logistic regression of y=1 (type is "diabetic") on all variables using R's built-in function and report the b vector.

```{r}
b_vec = coef(glm(y ~ X[, "glu"], family = "binomial"))
b_vec
```
Predict the probability of diabetes for someone with a blood sugar of 150.

```{r}
p = predict(glm(y ~ glu, family = "binomial", data = X), newdata = data.frame(glu = 150), type = "response")
p
```

For 100 people with blood sugar of 150, what is the probability more than 75 of them have diabetes? (You may need to review 241 to do this problem).

```{r}
1 - pbinom(75, size = 100, prob = p)
```

Plot the in-sample log-odds predictions (y-axis) versus the real response values (x-axis).

```{r}
p_hat=glm(y ~ X[, "glu"], family = "binomial")$fitted.values
log_odds_hat=log(p_hat/(1-p_hat))
ggplot(data.frame(log_odds_hat=log_odds_hat, has_diabetes=pima$type))+
  aes(x=has_diabetes, y=log_odds_hat)+
  geom_boxplot()
```

Plot the in-sample probability predictions (y-axis) versus the real response values (x-axis).

```{r}
ggplot(data.frame(p_hat = p_hat, has_diabetes = pima$type))+
  aes(x = has_diabetes, y = p_hat)+
  geom_boxplot()
```

Comment on how well you think the logistic regression performed in-sample.

It does well but it's not perfect since it makes more accurate preditctions for people with diabetes. 

Calculate the in-sample Brier score.

```{r}
score = mean((y - p_hat)^2)
score
```

Calculate the in-sample log-scoring rule.

```{r}
log_score = -mean(y * log(p_hat) + (1 - y) * log(1 - p_hat))
log_score
```


Run a probit regression of y=1 (type is "diabetic") on all variables using R's built-in function and report the b vector.


```{r}
probit_model = glm(y ~ ., family = binomial(link = "probit"), data = X)
b_vec = coef(probit_model)
b_vec
```

Does the weight estimates here in the probit fit have different signs than the weight estimates in the logistic fit? What does that mean?

The signs are different. This could be because the logistic regression is more sensitive to outliers.

Plot the in-sample probability predictions (y-axis) versus the real response values (x-axis).

```{r}
ggplot(data.frame(p_hat = p_hat, has_diabetes = pima$type)) +
  aes(x = has_diabetes, y = p_hat) +
  geom_boxplot()
```

Calculate the in-sample Brier score.

```{r}
briers = mean((y - p_hat)^2)
briers
```

Calculate the in-sample log-scoring rule.

```{r}
log_score = -mean(y * log(p_hat) + (1 - y) * log(1 - p_hat))
log_score
```

Which model did better in-sample?

They did the same

Compare both model oos using the Brier score and a test set with 1/3 of the data.

```{r}
#split
install.packages("caret")
library("caret")
partition = createDataPartition(data$diabetic, p = 2/3, list = FALSE)
train = data[partition, ]
test = data[-partition, ]

#logit model
m1 = glm(diabetic ~ ., family = binomial(link = "logit"), data = train)
probabilities_logit = predict(m1, newdata = test, type = "response")

#probit model
m2 = glm(diabetic ~ ., family = binomial(link = "probit"), data = train)
probabilities_probit = predict(m2, newdata = test, type = "response")

#brier scores
brier_score_logit = brier(probabilities_logit, test$diabetic)
brier_score_probit = brier(probabilities_probit, test$diabetic)

brier_score_model1
brier_score_model2
```

Which model did better oos?

#TO-DO

